{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NvlAaer28Bc9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import shutil, zipfile, os\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","import matplotlib.pyplot as plt\n","\n","# 1) Mount \u0026 unpack\n","drive.mount('/content/drive')\n","shutil.copy(\"/content/drive/MyDrive/DATASET.zip\", \"/content/\")\n","with zipfile.ZipFile(\"DATASET.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"dataset\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qWKRTa_Q9q6u"},"outputs":[],"source":["def load_images_from_folder(folder_path, image_size=(224, 224)):\n","    X, y = [], []\n","    class_names = sorted(os.listdir(folder_path))\n","    class_map = {n:i for i,n in enumerate(class_names)}\n","    for cls in class_names:\n","        folder = os.path.join(folder_path, cls)\n","        for f in os.listdir(folder):\n","            try:\n","                img = Image.open(os.path.join(folder, f)).convert('RGB').resize(image_size)\n","                X.append(np.array(img))\n","                y.append(class_map[cls])\n","            except:\n","                continue\n","    return np.array(X)/255.0, np.array(y), class_map\n","\n","X, y, class_map = load_images_from_folder(\"dataset/DATASET\")\n","class_names = list(class_map.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IAYxHWYm9q8l"},"outputs":[],"source":["X_train, X_temp, y_train, y_temp = train_test_split(\n","    X, y, test_size=0.3, stratify=y, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(\n","    X_temp, y_temp, test_size=2/3, stratify=y_temp, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_CEA79Oz9q-e"},"outputs":[],"source":["class_weights = compute_class_weight(\n","    'balanced', classes=np.unique(y_train), y=y_train)\n","class_weights = dict(enumerate(class_weights))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hKIDExx99rAv"},"outputs":[],"source":["train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=20,\n","    zoom_range=0.2,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"GjTWujjG9rCv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003eModel: \"MobileNetV2_Fashion\"\u003c/span\u003e\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1mModel: \"MobileNetV2_Fashion\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u003cspan style=\"font-weight: bold\"\u003e Layer (type)                    \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e Output Shape           \u003c/span\u003e┃\u003cspan style=\"font-weight: bold\"\u003e       Param # \u003c/span\u003e┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eInputLayer\u003c/span\u003e)      │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e224\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e3\u003c/span\u003e)    │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e7\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)     │     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,257,984\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eFunctional\u003c/span\u003e)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1280\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eGlobalAveragePooling2D\u003c/span\u003e)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                   │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1024\u003c/span\u003e)           │     \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1,311,744\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1024\u003c/span\u003e)           │         \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4,096\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBatchNormalization\u003c/span\u003e)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)               │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1024\u003c/span\u003e)           │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                 │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e512\u003c/span\u003e)            │       \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e524,800\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e512\u003c/span\u003e)            │         \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,048\u003c/span\u003e │\n","│ (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eBatchNormalization\u003c/span\u003e)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDropout\u003c/span\u003e)             │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e512\u003c/span\u003e)            │             \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e0\u003c/span\u003e │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u003cspan style=\"color: #0087ff; text-decoration-color: #0087ff\"\u003eDense\u003c/span\u003e)                 │ (\u003cspan style=\"color: #00d7ff; text-decoration-color: #00d7ff\"\u003eNone\u003c/span\u003e, \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e10\u003c/span\u003e)             │         \u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e5,130\u003c/span\u003e │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","\u003c/pre\u003e\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n","│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,311,744\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Total params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e4,105,802\u003c/span\u003e (15.66 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,105,802\u001b[0m (15.66 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e1,844,746\u003c/span\u003e (7.04 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,844,746\u001b[0m (7.04 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cpre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"\u003e\u003cspan style=\"font-weight: bold\"\u003e Non-trainable params: \u003c/span\u003e\u003cspan style=\"color: #00af00; text-decoration-color: #00af00\"\u003e2,261,056\u003c/span\u003e (8.63 MB)\n","\u003c/pre\u003e\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,261,056\u001b[0m (8.63 MB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["input_shape = (224, 224, 3)\n","num_classes = len(class_map)\n","\n","# Load the pretrained MobileNetV2, omit its top\n","base_model = tf.keras.applications.MobileNetV2(\n","    weights='imagenet', include_top=False, input_shape=input_shape)\n","base_model.trainable = False  # freeze backbone\n","\n","# Add custom head\n","inputs = Input(shape=input_shape)\n","x = base_model(inputs, training=False)\n","x = layers.GlobalAveragePooling2D()(x)\n","\n","x = layers.Dense(1024, activation='relu')(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dropout(0.5)(x)\n","\n","x = layers.Dense(512, activation='relu')(x)\n","x = layers.BatchNormalization()(x)\n","x = layers.Dropout(0.5)(x)\n","\n","outputs = layers.Dense(num_classes, activation='softmax')(x)\n","model = models.Model(inputs, outputs, name='MobileNetV2_Fashion')\n","\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"QiBfsrSF9rEw"},"outputs":[],"source":["model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sahj0bFo9rGt"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1304 - loss: 3.5895 - val_accuracy: 0.4600 - val_loss: 1.7261\n","Epoch 2/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 405ms/step - accuracy: 0.4435 - loss: 1.7892 - val_accuracy: 0.7000 - val_loss: 1.2082\n","Epoch 3/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 330ms/step - accuracy: 0.6244 - loss: 1.3128 - val_accuracy: 0.7900 - val_loss: 0.8988\n","Epoch 4/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 399ms/step - accuracy: 0.6738 - loss: 1.0294 - val_accuracy: 0.8300 - val_loss: 0.6974\n","Epoch 5/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 376ms/step - accuracy: 0.7357 - loss: 0.8248 - val_accuracy: 0.8500 - val_loss: 0.5660\n","Epoch 6/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 327ms/step - accuracy: 0.8021 - loss: 0.6664 - val_accuracy: 0.8600 - val_loss: 0.4907\n","Epoch 7/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.7906 - loss: 0.7048 - val_accuracy: 0.8800 - val_loss: 0.4280\n","Epoch 8/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.7960 - loss: 0.5902 - val_accuracy: 0.8700 - val_loss: 0.3738\n","Epoch 9/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 330ms/step - accuracy: 0.7995 - loss: 0.5933 - val_accuracy: 0.8700 - val_loss: 0.3428\n","Epoch 10/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 404ms/step - accuracy: 0.8084 - loss: 0.5757 - val_accuracy: 0.8700 - val_loss: 0.3192\n","Epoch 11/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.8541 - loss: 0.4152 - val_accuracy: 0.9000 - val_loss: 0.2977\n","Epoch 12/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 330ms/step - accuracy: 0.8512 - loss: 0.4197 - val_accuracy: 0.9000 - val_loss: 0.2824\n","Epoch 13/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.8737 - loss: 0.3711 - val_accuracy: 0.9000 - val_loss: 0.2615\n","Epoch 14/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.8516 - loss: 0.4226 - val_accuracy: 0.8900 - val_loss: 0.2602\n","Epoch 15/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - accuracy: 0.8689 - loss: 0.3760 - val_accuracy: 0.9100 - val_loss: 0.2519\n","Epoch 16/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 408ms/step - accuracy: 0.8897 - loss: 0.3312 - val_accuracy: 0.9000 - val_loss: 0.2515\n","Epoch 17/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.9020 - loss: 0.2914 - val_accuracy: 0.9100 - val_loss: 0.2380\n","Epoch 18/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - accuracy: 0.8768 - loss: 0.3997 - val_accuracy: 0.9100 - val_loss: 0.2419\n","Epoch 19/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 400ms/step - accuracy: 0.8840 - loss: 0.3386 - val_accuracy: 0.9000 - val_loss: 0.2678\n","Epoch 20/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 326ms/step - accuracy: 0.8912 - loss: 0.3402 - val_accuracy: 0.9000 - val_loss: 0.2646\n","Epoch 21/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 401ms/step - accuracy: 0.9033 - loss: 0.2383 - val_accuracy: 0.9100 - val_loss: 0.2507\n","Epoch 22/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 397ms/step - accuracy: 0.9187 - loss: 0.2761 - val_accuracy: 0.9000 - val_loss: 0.2290\n","Epoch 23/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - accuracy: 0.9359 - loss: 0.2457 - val_accuracy: 0.9000 - val_loss: 0.2584\n","Epoch 24/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 397ms/step - accuracy: 0.8897 - loss: 0.2992 - val_accuracy: 0.8700 - val_loss: 0.2705\n","Epoch 25/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.9281 - loss: 0.2200 - val_accuracy: 0.8800 - val_loss: 0.2804\n","Epoch 26/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 328ms/step - accuracy: 0.9090 - loss: 0.2728 - val_accuracy: 0.8800 - val_loss: 0.3043\n","Epoch 27/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.9066 - loss: 0.2545 - val_accuracy: 0.8900 - val_loss: 0.2875\n","Epoch 28/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9237 - loss: 0.2254 - val_accuracy: 0.9000 - val_loss: 0.2573\n","Epoch 29/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 327ms/step - accuracy: 0.9399 - loss: 0.2005 - val_accuracy: 0.9000 - val_loss: 0.2697\n","Epoch 30/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 400ms/step - accuracy: 0.8883 - loss: 0.2881 - val_accuracy: 0.8900 - val_loss: 0.2683\n","Epoch 31/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9407 - loss: 0.2070 - val_accuracy: 0.8900 - val_loss: 0.2645\n","Epoch 32/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 323ms/step - accuracy: 0.9406 - loss: 0.1899 - val_accuracy: 0.9000 - val_loss: 0.2533\n","Epoch 33/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 407ms/step - accuracy: 0.9433 - loss: 0.2425 - val_accuracy: 0.8900 - val_loss: 0.2733\n","Epoch 34/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.9259 - loss: 0.2305 - val_accuracy: 0.9000 - val_loss: 0.2758\n","Epoch 35/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 405ms/step - accuracy: 0.9481 - loss: 0.1669 - val_accuracy: 0.9000 - val_loss: 0.2804\n","Epoch 36/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403ms/step - accuracy: 0.9406 - loss: 0.1788 - val_accuracy: 0.8900 - val_loss: 0.2886\n","Epoch 37/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9406 - loss: 0.1711 - val_accuracy: 0.8900 - val_loss: 0.2518\n","Epoch 38/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 325ms/step - accuracy: 0.9431 - loss: 0.1634 - val_accuracy: 0.8900 - val_loss: 0.2631\n","Epoch 39/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 402ms/step - accuracy: 0.9451 - loss: 0.1843 - val_accuracy: 0.8900 - val_loss: 0.2605\n","Epoch 40/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9537 - loss: 0.1378 - val_accuracy: 0.9000 - val_loss: 0.2606\n","Epoch 41/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 326ms/step - accuracy: 0.9278 - loss: 0.1832 - val_accuracy: 0.9100 - val_loss: 0.2540\n","Epoch 42/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - accuracy: 0.9465 - loss: 0.1644 - val_accuracy: 0.9200 - val_loss: 0.2417\n","Epoch 43/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.9307 - loss: 0.1972 - val_accuracy: 0.9200 - val_loss: 0.2340\n","Epoch 44/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 336ms/step - accuracy: 0.9445 - loss: 0.1551 - val_accuracy: 0.9100 - val_loss: 0.2421\n","Epoch 45/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - accuracy: 0.9459 - loss: 0.1565 - val_accuracy: 0.9200 - val_loss: 0.2493\n","Epoch 46/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9646 - loss: 0.1289 - val_accuracy: 0.9300 - val_loss: 0.2443\n","Epoch 47/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 326ms/step - accuracy: 0.9427 - loss: 0.1533 - val_accuracy: 0.9100 - val_loss: 0.2470\n","Epoch 48/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 401ms/step - accuracy: 0.9606 - loss: 0.1491 - val_accuracy: 0.8900 - val_loss: 0.2372\n","Epoch 49/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9555 - loss: 0.1385 - val_accuracy: 0.9000 - val_loss: 0.2291\n","Epoch 50/50\n","\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 322ms/step - accuracy: 0.9509 - loss: 0.1253 - val_accuracy: 0.8900 - val_loss: 0.2384\n"]}],"source":["history = model.fit(\n","    train_datagen.flow(X_train, y_train, batch_size=32),\n","    validation_data=(X_val, y_val),\n","    epochs=50,\n","    class_weight=class_weights,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"srzVpVa29-DI"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 617ms/step - accuracy: 0.8950 - loss: 0.3431\n","Test Accuracy: 0.8900\n"]}],"source":["test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {test_acc:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RZuWzYwS99_m"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["model.save('/content/drive/My Drive/Collab Notebooks/fashion_product_mobilenet.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"puqiBITx998a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gradio\n","  Downloading gradio-5.31.0-py3-none-any.whl.metadata (16 kB)\n","Collecting aiofiles\u003c25.0,\u003e=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio\u003c5.0,\u003e=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi\u003c1.0,\u003e=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.1 (from gradio)\n","  Downloading gradio_client-1.10.1-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx\u003e=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub\u003e=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.2)\n","Requirement already satisfied: jinja2\u003c4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe\u003c4.0,\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: numpy\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow\u003c12.0,\u003e=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic\u003c2.12,\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart\u003e=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: pyyaml\u003c7.0,\u003e=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Collecting ruff\u003e=0.9.3 (from gradio)\n","  Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx\u003c0.2.0,\u003e=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette\u003c1.0,\u003e=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit\u003c0.14.0,\u003e=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer\u003c1.0,\u003e=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn\u003e=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1-\u003egradio) (2025.3.2)\n","Requirement already satisfied: websockets\u003c16.0,\u003e=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1-\u003egradio) (15.0.1)\n","Requirement already satisfied: idna\u003e=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5.0,\u003e=3.0-\u003egradio) (3.10)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio\u003c5.0,\u003e=3.0-\u003egradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx\u003e=0.24.1-\u003egradio) (1.0.9)\n","Requirement already satisfied: h11\u003e=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*-\u003ehttpx\u003e=0.24.1-\u003egradio) (0.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (3.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.28.1-\u003egradio) (4.67.1)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2025.2)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (2.33.2)\n","Requirement already satisfied: typing-inspection\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c2.12,\u003e=2.0-\u003egradio) (0.4.0)\n","Requirement already satisfied: click\u003e=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (8.2.0)\n","Requirement already satisfied: shellingham\u003e=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (1.5.4)\n","Requirement already satisfied: rich\u003e=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer\u003c1.0,\u003e=0.12-\u003egradio) (13.9.4)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas\u003c3.0,\u003e=1.0-\u003egradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.28.1-\u003egradio) (3.4.2)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.28.1-\u003egradio) (2.4.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=10.11.0-\u003etyper\u003c1.0,\u003e=0.12-\u003egradio) (0.1.2)\n","Downloading gradio-5.31.0-py3-none-any.whl (54.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.1-py3-none-any.whl (323 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.11-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.31.0 gradio-client-1.10.1 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.11 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://eaed9d75fb75856eac.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["\u003cdiv\u003e\u003ciframe src=\"https://eaed9d75fb75856eac.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen\u003e\u003c/iframe\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["!pip install gradio\n","import gradio as gr\n","\n","def predict_fashion(img):\n","    img = img.resize((224,224))\n","    arr = np.array(img)/255.0\n","    pred = model.predict(arr[np.newaxis,...])\n","    return class_names[np.argmax(pred)]\n","\n","iface = gr.Interface(\n","    fn=predict_fashion,\n","    inputs=gr.Image(type=\"pil\"),\n","    outputs=\"text\",\n","    live=True,\n","    title=\"Fashion Classifier (MobileNetV2)\",\n","    description=\"Upload an image to classify.\"\n",")\n","iface.launch(share=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"b5VtHrE-995M"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 212ms/step\n","\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 575ms/step\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step\n","🔹 AUC - Train: 0.9998, Validation: 0.9959, Test: 0.9899\n","🔹 Accuracy - Train: 0.9871, Validation: 0.8900, Test: 0.8900\n","🔹 Loss - Train: 0.0315, Validation: 0.2384, Test: 0.3761\n","🔹 Precision (Weighted): 0.8974, (Macro): 0.8766\n","🔹 Recall (Sensitivity) (Weighted): 0.8900, (Macro): 0.8750\n","🔹 F1-Score (Weighted): 0.8907, (Macro): 0.8726\n","🔹 Specificity (approx): 0.9879\n","🔹 Classification Miss Rate: 0.1100\n","\n","🔹 Confusion Matrix:\n"," [[20  0  0  0  0  0  0  0  0  0]\n"," [ 0 13  0  0  0  0  0  7  0  0]\n"," [ 0  0 30  0  0  0  0  0  0  0]\n"," [ 0  0  0  7  0  0  0  0  0  3]\n"," [ 0  0  0  0 20  0  0  0  0  0]\n"," [ 1  0  0  1  0 17  0  0  0  1]\n"," [ 0  0  0  0  2  0 18  0  0  0]\n"," [ 0  3  0  0  0  0  0 17  0  0]\n"," [ 0  0  0  0  0  0  0  0 20  0]\n"," [ 0  0  0  4  0  0  0  0  0 16]]\n","\n","🔹 Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.95      1.00      0.98        20\n","           1       0.81      0.65      0.72        20\n","           2       1.00      1.00      1.00        30\n","           3       0.58      0.70      0.64        10\n","           4       0.91      1.00      0.95        20\n","           5       1.00      0.85      0.92        20\n","           6       1.00      0.90      0.95        20\n","           7       0.71      0.85      0.77        20\n","           8       1.00      1.00      1.00        20\n","           9       0.80      0.80      0.80        20\n","\n","    accuracy                           0.89       200\n","   macro avg       0.88      0.88      0.87       200\n","weighted avg       0.90      0.89      0.89       200\n","\n"]}],"source":["from sklearn.metrics import (\n","    precision_score, recall_score, f1_score, roc_auc_score,\n","    confusion_matrix, classification_report\n",")\n","import numpy as np\n","\n","# Predict probabilities\n","train_preds = model.predict(X_train)\n","val_preds = model.predict(X_val)\n","test_preds = model.predict(X_test)\n","\n","# Convert probabilities to predicted class labels\n","train_preds_class = np.argmax(train_preds, axis=1)\n","val_preds_class = np.argmax(val_preds, axis=1)\n","test_preds_class = np.argmax(test_preds, axis=1)\n","\n","# True labels (assuming already integers)\n","y_train_class = y_train\n","y_val_class = y_val\n","y_test_class = y_test\n","\n","# AUC Scores\n","train_auc = roc_auc_score(y_train, train_preds, multi_class='ovr')\n","val_auc = roc_auc_score(y_val, val_preds, multi_class='ovr')\n","test_auc = roc_auc_score(y_test, test_preds, multi_class='ovr')\n","\n","# Accuracy\n","train_accuracy = np.mean(train_preds_class == y_train_class)\n","val_accuracy = np.mean(val_preds_class == y_val_class)\n","test_accuracy = np.mean(test_preds_class == y_test_class)\n","\n","# Loss\n","train_loss = model.evaluate(X_train, y_train, verbose=0)[0]\n","val_loss = model.evaluate(X_val, y_val, verbose=0)[0]\n","test_loss = model.evaluate(X_test, y_test, verbose=0)[0]\n","\n","# Precision, Recall, F1-Score (Weighted \u0026 Macro)\n","precision_weighted = precision_score(y_test_class, test_preds_class, average='weighted')\n","recall_weighted = recall_score(y_test_class, test_preds_class, average='weighted')\n","f1_weighted = f1_score(y_test_class, test_preds_class, average='weighted')\n","\n","precision_macro = precision_score(y_test_class, test_preds_class, average='macro')\n","recall_macro = recall_score(y_test_class, test_preds_class, average='macro')\n","f1_macro = f1_score(y_test_class, test_preds_class, average='macro')\n","\n","# Sensitivity = Recall (Weighted)\n","sensitivity = recall_weighted\n","\n","# Specificity (approximate for multiclass): TN / (TN + FP) averaged\n","conf_matrix = confusion_matrix(y_test_class, test_preds_class)\n","FP = conf_matrix.sum(axis=0) - np.diag(conf_matrix)\n","FN = conf_matrix.sum(axis=1) - np.diag(conf_matrix)\n","TP = np.diag(conf_matrix)\n","TN = conf_matrix.sum() - (FP + FN + TP)\n","specificity = np.mean(TN / (TN + FP))\n","\n","# Classification Miss Rate\n","miss_rate = 1 - sensitivity\n","\n","# Output all metrics\n","print(f\"🔹 AUC - Train: {train_auc:.4f}, Validation: {val_auc:.4f}, Test: {test_auc:.4f}\")\n","print(f\"🔹 Accuracy - Train: {train_accuracy:.4f}, Validation: {val_accuracy:.4f}, Test: {test_accuracy:.4f}\")\n","print(f\"🔹 Loss - Train: {train_loss:.4f}, Validation: {val_loss:.4f}, Test: {test_loss:.4f}\")\n","print(f\"🔹 Precision (Weighted): {precision_weighted:.4f}, (Macro): {precision_macro:.4f}\")\n","print(f\"🔹 Recall (Sensitivity) (Weighted): {recall_weighted:.4f}, (Macro): {recall_macro:.4f}\")\n","print(f\"🔹 F1-Score (Weighted): {f1_weighted:.4f}, (Macro): {f1_macro:.4f}\")\n","print(f\"🔹 Specificity (approx): {specificity:.4f}\")\n","print(f\"🔹 Classification Miss Rate: {miss_rate:.4f}\")\n","print(\"\\n🔹 Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\n🔹 Classification Report:\\n\", classification_report(y_test_class, test_preds_class))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eIxBJtfDDWf_"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","🔹 F2-Score (Weighted): 0.8896\n","🔹 F0.5-Score (Weighted): 0.8940\n","🔹 Positive Predictive Value (PPV): 0.8974\n","🔹 Negative Predictive Value (NPV): 0.9879\n","🔹 False Positive Rate (FPR): 0.0121\n","🔹 False Negative Rate (FNR): 0.1250\n","🔹 Likelihood Ratio Positive (LR+): 73.6998\n","🔹 Likelihood Ratio Negative (LR−): 0.1113\n","🔹 Fowlkes–Mallows Index (FMI): 0.8758\n"]}],"source":["from sklearn.metrics import (\n","    confusion_matrix, fbeta_score, precision_score, recall_score, f1_score\n",")\n","import numpy as np\n","\n","# Predict classes\n","test_preds = model.predict(X_test)\n","test_preds_class = np.argmax(test_preds, axis=1)\n","y_true = y_test  # assumed to be integer-encoded\n","\n","# Confusion Matrix\n","cm = confusion_matrix(y_true, test_preds_class)\n","TP = np.diag(cm)\n","FP = cm.sum(axis=0) - TP\n","FN = cm.sum(axis=1) - TP\n","TN = cm.sum() - (FP + FN + TP)\n","\n","# Small value to prevent divide-by-zero\n","eps = 1e-10\n","\n","# F2-Score (beta=2)\n","f2_score_weighted = fbeta_score(y_true, test_preds_class, average='weighted', beta=2)\n","\n","# Fβ-Score for general beta (set your desired beta)\n","beta = 0.5\n","f_beta_score_weighted = fbeta_score(y_true, test_preds_class, average='weighted', beta=beta)\n","\n","# Positive Predictive Value (Precision)\n","ppv = precision_score(y_true, test_preds_class, average='weighted')\n","\n","# Negative Predictive Value (NPV)\n","npv = np.mean(TN / (TN + FN + eps))\n","\n","# False Positive Rate (FPR)\n","fpr = np.mean(FP / (FP + TN + eps))\n","\n","# False Negative Rate (FNR)\n","fnr = np.mean(FN / (FN + TP + eps))\n","\n","# Likelihood Ratios\n","sensitivity = recall_score(y_true, test_preds_class, average='weighted')\n","specificity = np.mean(TN / (TN + FP + eps))\n","\n","lr_positive = sensitivity / (1 - specificity + eps)\n","lr_negative = (1 - sensitivity) / (specificity + eps)\n","\n","# Fowlkes–Mallows Index (FMI)\n","precision_macro = precision_score(y_true, test_preds_class, average='macro')\n","recall_macro = recall_score(y_true, test_preds_class, average='macro')\n","fmi = np.sqrt(precision_macro * recall_macro)\n","\n","# Print Results\n","print(f\"🔹 F2-Score (Weighted): {f2_score_weighted:.4f}\")\n","print(f\"🔹 F{beta}-Score (Weighted): {f_beta_score_weighted:.4f}\")\n","print(f\"🔹 Positive Predictive Value (PPV): {ppv:.4f}\")\n","print(f\"🔹 Negative Predictive Value (NPV): {npv:.4f}\")\n","print(f\"🔹 False Positive Rate (FPR): {fpr:.4f}\")\n","print(f\"🔹 False Negative Rate (FNR): {fnr:.4f}\")\n","print(f\"🔹 Likelihood Ratio Positive (LR+): {lr_positive:.4f}\")\n","print(f\"🔹 Likelihood Ratio Negative (LR−): {lr_negative:.4f}\")\n","print(f\"🔹 Fowlkes–Mallows Index (FMI): {fmi:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMnGofD7DWdv"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2qJU0PWKDWbj"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vXKt452DWZc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdLMQdzoDWXH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdawH5A-DWU5"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMrPcRQVInYVnJz6DYYY91r","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}